# 1. Import the necessary packages 
import tensorflow as tf 
from tensorflow.keras.models import Sequential 
from tensorflow.keras.layers import Dense, Flatten 
from tensorflow.keras.optimizers import SGD 
import matplotlib.pyplot as plt 
# 2. Load the training and testing data (MNIST) 
from tensorflow.keras.datasets import mnist 
(x_train, y_train), (x_test, y_test) = mnist.load_data() 
# Normalize pixel values (0–255 → 0–1) 
x_train = x_train.astype("float32") / 255.0 
x_test = x_test.astype("float32") / 255.0 
print("Training data shape:", x_train.shape) 
print("Testing data shape:", x_test.shape) 
# 3. Define the network architecture 
model = Sequential([ 
Flatten(input_shape=(28, 28)),       
Dense(256, activation="relu"),       
Dense(128, activation="relu"),       
Dense(10, activation="softmax")   ])    


 
# 4. Compile the model using SGD 
opt = SGD(learning_rate=0.01, momentum=0.9) 
model.compile(optimizer=opt, 
              loss="sparse_categorical_crossentropy", 
              metrics=["accuracy"]) 
 
# 5. Train the model 
history = model.fit(x_train, y_train, 
                    validation_data=(x_test, y_test), 
                    epochs=10, 
                    batch_size=64, 
                    verbose=1) 
 
# 6. Evaluate the network 
test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0) 
print(f"\nTest Loss: {test_loss:.4f}") 
print(f"Test Accuracy: {test_acc:.4f}") 
 
# 7. Plot training loss and accuracy 
plt.figure(figsize=(12, 5)) 
 
# Plot Loss 
plt.subplot(1, 2, 1) 
plt.plot(history.history["loss"], label="Train Loss") 
plt.plot(history.history["val_loss"], label="Validation Loss") 
plt.title("Training & Validation Loss") 
plt.xlabel("Epochs") 
plt.ylabel("Loss") 
plt.legend() 
# Plot Accuracy 
plt.subplot(1, 2, 2) 
plt.plot(history.history["accuracy"], label="Train Accuracy") 
plt.plot(history.history["val_accuracy"], label="Validation Accuracy") 
plt.title("Training & Validation Accuracy") 
plt.xlabel("Epochs") 
plt.ylabel("Accuracy") 
plt.legend() 
plt.show()
